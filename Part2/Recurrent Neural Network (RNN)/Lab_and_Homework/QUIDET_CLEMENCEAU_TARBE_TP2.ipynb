{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QUIDET_CLEMENCEAU_TARBE_TP2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB6vqasNmZJU",
        "outputId": "e5041497-b30c-48e8-90e0-33c2e2409a93"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "X = np.random.randint(2, size = (40,10))\r\n",
        "Y = np.zeros((40,1), dtype=int)\r\n",
        "for i in range(40):\r\n",
        "  Y[i] = np.sum(X[i])\r\n",
        "x_train = X[0:30]\r\n",
        "x_test = X[30:40]\r\n",
        "\r\n",
        "print(\"==========X=============\")\r\n",
        "print(X)\r\n",
        "print(\"==========Y=============\")\r\n",
        "print(Y)\r\n",
        "print(\"==========x_train=======\")\r\n",
        "print(x_train)\r\n",
        "print(\"==========x_test=======\")\r\n",
        "print(x_test)\r\n",
        "y_train = Y[0:30]\r\n",
        "y_test = Y[30:40]\r\n",
        "print(\"==========y_train=======\")\r\n",
        "print(y_train)\r\n",
        "print(\"==========y_test=======\")\r\n",
        "print(y_test)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==========X=============\n",
            "[[1 0 0 0 0 1 0 1 0 0]\n",
            " [0 1 1 0 0 0 1 1 1 1]\n",
            " [1 1 0 0 0 0 1 0 1 0]\n",
            " [1 0 0 0 0 1 1 1 1 0]\n",
            " [0 1 0 1 0 1 1 1 0 0]\n",
            " [1 1 0 1 0 1 1 1 0 1]\n",
            " [0 0 0 0 0 0 1 1 1 0]\n",
            " [0 0 1 0 1 0 1 1 0 0]\n",
            " [1 1 1 1 1 1 0 0 1 1]\n",
            " [1 0 1 0 0 1 0 0 0 1]\n",
            " [0 0 1 0 0 1 0 1 0 0]\n",
            " [0 1 1 1 0 0 1 1 0 0]\n",
            " [1 1 0 0 1 1 1 0 0 1]\n",
            " [0 0 0 1 1 0 1 0 0 0]\n",
            " [0 1 1 1 0 0 1 0 0 1]\n",
            " [0 1 0 0 0 0 0 0 1 1]\n",
            " [0 1 1 0 1 1 0 1 1 0]\n",
            " [1 1 0 0 0 1 0 0 1 0]\n",
            " [1 0 1 1 0 1 0 0 1 0]\n",
            " [1 1 1 0 1 1 1 1 0 1]\n",
            " [1 0 0 1 1 1 1 0 1 0]\n",
            " [0 1 1 1 1 1 1 0 1 0]\n",
            " [0 1 1 1 1 0 0 0 1 0]\n",
            " [0 1 0 0 1 0 0 0 0 0]\n",
            " [1 1 1 1 1 0 1 1 1 0]\n",
            " [1 1 0 1 1 1 1 0 1 1]\n",
            " [1 1 0 0 1 1 1 1 1 0]\n",
            " [1 0 0 0 1 1 1 1 1 0]\n",
            " [0 1 0 1 0 0 1 0 0 0]\n",
            " [1 1 1 1 0 1 0 0 0 0]\n",
            " [0 0 1 1 1 1 0 1 1 0]\n",
            " [0 1 0 0 1 1 0 0 1 1]\n",
            " [1 1 0 0 1 0 0 1 0 0]\n",
            " [1 1 1 0 1 1 0 1 0 0]\n",
            " [1 0 1 0 0 0 0 0 1 0]\n",
            " [1 1 0 1 1 0 0 1 0 1]\n",
            " [0 1 1 0 1 0 1 0 1 0]\n",
            " [1 1 0 1 0 1 1 1 1 0]\n",
            " [1 1 1 0 0 0 0 1 0 1]\n",
            " [1 1 0 0 1 1 0 1 0 0]]\n",
            "==========Y=============\n",
            "[[3]\n",
            " [6]\n",
            " [4]\n",
            " [5]\n",
            " [5]\n",
            " [7]\n",
            " [3]\n",
            " [4]\n",
            " [8]\n",
            " [4]\n",
            " [3]\n",
            " [5]\n",
            " [6]\n",
            " [3]\n",
            " [5]\n",
            " [3]\n",
            " [6]\n",
            " [4]\n",
            " [5]\n",
            " [8]\n",
            " [6]\n",
            " [7]\n",
            " [5]\n",
            " [2]\n",
            " [8]\n",
            " [8]\n",
            " [7]\n",
            " [6]\n",
            " [3]\n",
            " [5]\n",
            " [6]\n",
            " [5]\n",
            " [4]\n",
            " [6]\n",
            " [3]\n",
            " [6]\n",
            " [5]\n",
            " [7]\n",
            " [5]\n",
            " [5]]\n",
            "==========x_train=======\n",
            "[[1 0 0 0 0 1 0 1 0 0]\n",
            " [0 1 1 0 0 0 1 1 1 1]\n",
            " [1 1 0 0 0 0 1 0 1 0]\n",
            " [1 0 0 0 0 1 1 1 1 0]\n",
            " [0 1 0 1 0 1 1 1 0 0]\n",
            " [1 1 0 1 0 1 1 1 0 1]\n",
            " [0 0 0 0 0 0 1 1 1 0]\n",
            " [0 0 1 0 1 0 1 1 0 0]\n",
            " [1 1 1 1 1 1 0 0 1 1]\n",
            " [1 0 1 0 0 1 0 0 0 1]\n",
            " [0 0 1 0 0 1 0 1 0 0]\n",
            " [0 1 1 1 0 0 1 1 0 0]\n",
            " [1 1 0 0 1 1 1 0 0 1]\n",
            " [0 0 0 1 1 0 1 0 0 0]\n",
            " [0 1 1 1 0 0 1 0 0 1]\n",
            " [0 1 0 0 0 0 0 0 1 1]\n",
            " [0 1 1 0 1 1 0 1 1 0]\n",
            " [1 1 0 0 0 1 0 0 1 0]\n",
            " [1 0 1 1 0 1 0 0 1 0]\n",
            " [1 1 1 0 1 1 1 1 0 1]\n",
            " [1 0 0 1 1 1 1 0 1 0]\n",
            " [0 1 1 1 1 1 1 0 1 0]\n",
            " [0 1 1 1 1 0 0 0 1 0]\n",
            " [0 1 0 0 1 0 0 0 0 0]\n",
            " [1 1 1 1 1 0 1 1 1 0]\n",
            " [1 1 0 1 1 1 1 0 1 1]\n",
            " [1 1 0 0 1 1 1 1 1 0]\n",
            " [1 0 0 0 1 1 1 1 1 0]\n",
            " [0 1 0 1 0 0 1 0 0 0]\n",
            " [1 1 1 1 0 1 0 0 0 0]]\n",
            "==========x_test=======\n",
            "[[0 0 1 1 1 1 0 1 1 0]\n",
            " [0 1 0 0 1 1 0 0 1 1]\n",
            " [1 1 0 0 1 0 0 1 0 0]\n",
            " [1 1 1 0 1 1 0 1 0 0]\n",
            " [1 0 1 0 0 0 0 0 1 0]\n",
            " [1 1 0 1 1 0 0 1 0 1]\n",
            " [0 1 1 0 1 0 1 0 1 0]\n",
            " [1 1 0 1 0 1 1 1 1 0]\n",
            " [1 1 1 0 0 0 0 1 0 1]\n",
            " [1 1 0 0 1 1 0 1 0 0]]\n",
            "==========y_train=======\n",
            "[[3]\n",
            " [6]\n",
            " [4]\n",
            " [5]\n",
            " [5]\n",
            " [7]\n",
            " [3]\n",
            " [4]\n",
            " [8]\n",
            " [4]\n",
            " [3]\n",
            " [5]\n",
            " [6]\n",
            " [3]\n",
            " [5]\n",
            " [3]\n",
            " [6]\n",
            " [4]\n",
            " [5]\n",
            " [8]\n",
            " [6]\n",
            " [7]\n",
            " [5]\n",
            " [2]\n",
            " [8]\n",
            " [8]\n",
            " [7]\n",
            " [6]\n",
            " [3]\n",
            " [5]]\n",
            "==========y_test=======\n",
            "[[6]\n",
            " [5]\n",
            " [4]\n",
            " [6]\n",
            " [3]\n",
            " [6]\n",
            " [5]\n",
            " [7]\n",
            " [5]\n",
            " [5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKlWGRAODNdB"
      },
      "source": [
        "from random import random\n",
        "import numpy as np\n",
        "import math as m\n",
        "\n",
        "# Elman Recurrent Neural Network\n",
        "class RNN:\n",
        "\n",
        "    def __init__(self, x_train, x_test, y_train, y_test):\n",
        "        \n",
        "        self.I = 30 # Nombre de sÃ©quences \n",
        "        self.T = 8 # Nb de bits \n",
        "\n",
        "        self.x_train = x_train\n",
        "        self.x_test = x_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "\n",
        "        # learning rates\n",
        "        self.alpha1 = 0.01 \n",
        "        self.alpha2 = 0.01\n",
        "\n",
        "        # weights\n",
        "        self.Vx = random()\n",
        "        self.Vf = random()\n",
        "\n",
        "    def forward_prop(self, y_pred, Ft):\n",
        "      sommeF = 0\n",
        "      for i in range(self.I):\n",
        "          for t in range(self.T):\n",
        "              if (t == 0):\n",
        "                  Ft[i][t] = self.Vx * X[i][t]\n",
        "                  sommeF += Ft[i][t]\n",
        "              else :\n",
        "                  Ft[i][t] = self.Vf * Ft[i][t-1] + self.Vx * X[i][t]\n",
        "                  sommeF += Ft[i][t]\n",
        "          y_pred[i] = sommeF\n",
        "      return y_pred, Ft\n",
        "\n",
        "    #Back Propagation\n",
        "    def backward_prop(self):\n",
        "      y_pred = np.zeros(self.I)\n",
        "      Ft = np.zeros((self.I,self.T))\n",
        "      grad_Vx = 0\n",
        "      grad_Vf = 0\n",
        "      conv = 1\n",
        "\n",
        "      epoch = 0\n",
        "      while (epoch < 100):\n",
        "          #1st step : forward_prop    \n",
        "          y_pred, Ft = self.forward_prop(y_pred, Ft)\n",
        "\n",
        "          #2nd step : backward_prop      \n",
        "          Vx_back = self.Vx\n",
        "          Vf_back = self.Vf    \n",
        "          for i in range(self.I):\n",
        "              for t in range(self.T):\n",
        "                  # dE/dVx\n",
        "                  grad_Vx += (y_pred[i] - self.y_train[i]) * X[i][t] * np.power(self.Vf,(self.T - t))\n",
        "                  # dE/dVf\n",
        "                  grad_Vf += (y_pred[i] - self.y_train[i]) * Ft[i][t] * np.power(self.Vf,(self.T - t))\n",
        "          self.Vx -= self.alpha1 * grad_Vx\n",
        "          self.Vf -= self.alpha2 * grad_Vf\n",
        "\n",
        "          epoch+=1\n",
        "      conv = abs(self.Vx - Vx_back) + abs(self.Vf - Vf_back)   \n",
        "      #print(\"Y PRED: \\n\",y_pred)\n",
        "      return y_pred, conv\n",
        "\n",
        "    def backward_prop_results(self):\n",
        "      y_pred,conv = self.backward_prop()\n",
        "      print(\"y_train: \", self.y_train) \n",
        "      print(\"y_pred: \", y_pred)\n",
        "      print(\"(y_train - y_pred): \", self.y_train-y_pred)\n",
        "\n",
        "    def resilient_prop(self, y_train, dX=0.001, df=0.001, np=1.2, nn=.5):\n",
        "        grad_Vx = 0\n",
        "        grad_Vf = 0\n",
        "        conv = 1\n",
        "\n",
        "        epoch = 0\n",
        "        while(epoch<100):\n",
        "            #1st step : forward_prop\n",
        "            y_pred, Ft = self.forward_prop(y_pred, Ft)\n",
        "              \n",
        "            #2nd step : resilient_prop\n",
        "            Vx_back = self.Vx\n",
        "            Vf_back = self.Vf \n",
        "\n",
        "            for i in range(self.I):\n",
        "                for t in range(self.T):\n",
        "                    # dE/dVx\n",
        "                    grad_Vx += (y_pred[i] - self.y_train[i]) * X[i][t] * np.power(self.Vf,(self.T - t))\n",
        "                    # dE/dVf\n",
        "                    grad_Vf += (y_pred[i] - self.y_train[i]) * Ft[i][t] * np.power(self.Vf,(self.T - t))\n",
        "\n",
        "            #Vx_itera\n",
        "            dirVx =  Vx_back * grad_Vx\n",
        "            ampVx =  dX \n",
        "            if dirVx * ampVx >= 0 :\n",
        "                dX *= np\n",
        "            else:\n",
        "                dX *= nn\n",
        "            self.Vx -= self.Vx - m.copysign(dX, grad_Vx)\n",
        "\n",
        "            #Vf_itera\n",
        "            dirVf =  Vf_back * grad_Vf\n",
        "            ampVf =  df \n",
        "            if dirVf * ampVf >= 0 :\n",
        "                df *= np\n",
        "            else:\n",
        "                df *= nn\n",
        "            self.Vf = self.Vf - m.copysign(df, grad_Vf)\n",
        "            \n",
        "            epoch +=1 \n",
        "        conv = abs(self.Vx - Vx_back) + abs(self.Vf - Vf_back)\n",
        "        return y_pred, conv\n",
        "\n",
        "    def resilient_prop_results(self):        \n",
        "      y_pred,conv = self.resilient_prop()\n",
        "      print(\"y_train: \", self.y_train) \n",
        "      print(\"y_pred: \", y_pred)\n",
        "      print(\"(y_train - y_pred): \", self.y_train-y_pred)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c_2a4461NLAv",
        "outputId": "f37a2dc4-5e4c-4834-87fd-cff6b9b19b8c"
      },
      "source": [
        "recurrent_network = RNN(x_train, x_test, y_train, y_test)\n",
        "print(\"-------Backward Propagation------\")\n",
        "recurrent_network.backward_prop_results()\n",
        "print(\"-------Resilient Propagation------\")\n",
        "recurrent_network.resilient_prop_results()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------Backward Propagation------\n",
            "y_train:  [[3]\n",
            " [6]\n",
            " [4]\n",
            " [5]\n",
            " [5]\n",
            " [7]\n",
            " [3]\n",
            " [4]\n",
            " [8]\n",
            " [4]\n",
            " [3]\n",
            " [5]\n",
            " [6]\n",
            " [3]\n",
            " [5]\n",
            " [3]\n",
            " [6]\n",
            " [4]\n",
            " [5]\n",
            " [8]\n",
            " [6]\n",
            " [7]\n",
            " [5]\n",
            " [2]\n",
            " [8]\n",
            " [8]\n",
            " [7]\n",
            " [6]\n",
            " [3]\n",
            " [5]]\n",
            "y_pred:  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            "(y_train - y_pred):  [[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  nan nan nan nan nan nan nan nan nan nan nan nan]]\n",
            "-------Resilient Propagation------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: RuntimeWarning: overflow encountered in multiply\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:60: RuntimeWarning: overflow encountered in multiply\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in multiply\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in multiply\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in add\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-aa4d7909d483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrecurrent_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_prop_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------Resilient Propagation------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrecurrent_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresilient_prop_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-88639e7ab53e>\u001b[0m in \u001b[0;36mresilient_prop_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresilient_prop_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m       \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresilient_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_train: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_pred: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-88639e7ab53e>\u001b[0m in \u001b[0;36mresilient_prop\u001b[0;34m(y_train, dX, df, np, nn)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m#1st step : forward_prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m#2nd step : resilient_prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G82uJ4AzX_bp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-rAR_IyNSC7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}